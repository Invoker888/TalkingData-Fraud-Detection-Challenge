{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_count( df, group_cols, agg_name, agg_type='uint32', show_max=False):\n",
    "    print( \"do_count to \", group_cols , '...' )\n",
    "    gp = df[group_cols].groupby(group_cols).size().rename(agg_name).to_frame().reset_index()\n",
    "#     if debug:\n",
    "#         print(df[group_cols])\n",
    "# #         print(df[group_cols][group_cols]) # same to the former\n",
    "#         print(df[group_cols][group_cols].groupby(group_cols).size())\n",
    "    df = df.merge(gp, on=group_cols, how='left', copy=False)\n",
    "    del gp\n",
    "    if show_max:\n",
    "        print( agg_name + \" max value = \", df[agg_name].max())\n",
    "    df[agg_name] = df[agg_name].astype(agg_type,copy=False)\n",
    "    return( df )\n",
    "\n",
    "def do_countuniq( df, group_cols, counted, agg_name, agg_type='uint32', show_max=False):\n",
    "    print( \"Counting unqiue \", counted, \" by \", group_cols , '...' )\n",
    "    # print('the Id of train_df while function before merge: ',id(df)) # the same with train_df\n",
    "    gp = df[group_cols+[counted]].groupby(group_cols)[counted].nunique().reset_index().rename(columns={counted:agg_name})\n",
    "    df = df.merge(gp, on=group_cols, how='left', copy=False)\n",
    "    # print('the Id of train_df while function after merge: ',id(df)) # id changes\n",
    "    del gp\n",
    "    if show_max:\n",
    "        print( agg_name + \" max value = \", df[agg_name].max() )\n",
    "    df[agg_name] = df[agg_name].astype(agg_type,copy=False)\n",
    "    return( df )\n",
    "    \n",
    "def do_cumcount( df, group_cols, counted, agg_name, agg_type='uint32', show_max=False):\n",
    "    print( \"Cumulative count by \", group_cols , '...' )\n",
    "    gp = df[group_cols+[counted]].groupby(group_cols)[counted].cumcount() # 累加\n",
    "    df[agg_name]=gp.values\n",
    "    del gp\n",
    "    if show_max:\n",
    "        print( agg_name + \" max value = \", df[agg_name].max() )\n",
    "    df[agg_name] = df[agg_name].astype(agg_type,copy=False)\n",
    "    return( df )\n",
    "\n",
    "def do_mean( df, group_cols, counted, agg_name, agg_type='float32', show_max=False):\n",
    "    print( \"Calculating mean of \", counted, \" by \", group_cols , '...' )\n",
    "    gp = df[group_cols+[counted]].groupby(group_cols)[counted].mean().reset_index().rename(columns={counted:agg_name})\n",
    "    df = df.merge(gp, on=group_cols, how='left', copy=False)\n",
    "    del gp\n",
    "    if show_max:\n",
    "        print( agg_name + \" max value = \", df[agg_name].max() )\n",
    "    df[agg_name] = df[agg_name].astype(agg_type,copy=False)\n",
    "    return( df )\n",
    "\n",
    "def do_var( df, group_cols, counted, agg_name, agg_type='float32', show_max=False):\n",
    "    print( \"Calculating variance of \", counted, \" by \", group_cols , '...' )\n",
    "    gp = df[group_cols+[counted]].groupby(group_cols)[counted].var().reset_index().rename(columns={counted:agg_name})\n",
    "    df = df.merge(gp, on=group_cols, how='left', copy=False)\n",
    "    del gp\n",
    "    if show_max:\n",
    "        print( agg_name + \" max value = \", df[agg_name].max() )\n",
    "    df[agg_name] = df[agg_name].astype(agg_type,copy=False)\n",
    "    return( df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train data... 0 to 184903891\n",
      "loading test data...\n",
      "Combine test_df and train_df...\n",
      "Extracting hour and day and add 8h...\n",
      "Combining new features...\n",
      "Calculating mean of  channel  by  ['ip', 'app'] ...\n",
      "Calculating mean of  channel  by  ['ip', 'device'] ...\n",
      "vars and data type: \n",
      "Generate real testset from test_supplement...\n",
      "train size:  122070801            C0          C1\n",
      "0  278.586273  264.425903\n",
      "1  279.262939  262.869843\n",
      "2  271.784485  254.209656\n",
      "3  397.849213  274.730377\n",
      "4  294.650848  278.970825\n",
      "valid size:  62833089\n",
      "test size :  18790469\n",
      "Index(['C0', 'C1'], dtype='object')\n",
      "Converting train/valid into float32...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 122070801 entries, 0 to 122070800\n",
      "Data columns (total 2 columns):\n",
      "C0    float32\n",
      "C1    float32\n",
      "dtypes: float32(2)\n",
      "memory usage: 1.8 GB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 62833089 entries, 122070801 to 184903889\n",
      "Data columns (total 2 columns):\n",
      "C0    float32\n",
      "C1    float32\n",
      "dtypes: float32(2)\n",
      "memory usage: 958.8 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 18790469 entries, 206194766 to 239488148\n",
      "Data columns (total 2 columns):\n",
      "C0    float32\n",
      "C1    float32\n",
      "dtypes: float32(2)\n",
      "memory usage: 286.7 MB\n",
      "None\n",
      "Saving data to disk...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "\n",
    "# debug = True\n",
    "debug=False\n",
    "\n",
    "frm = 0\n",
    "to = 184903891\n",
    "nchunk=184903891 # entire dataset\n",
    "val_size=62833089  # since 9th 0:00:00\n",
    "if debug:\n",
    "    print('*** Debug: this is a test run for debugging purposes ***')\n",
    "    frm=0\n",
    "    nchunk=100000\n",
    "    val_size=10000\n",
    "    to = 100000\n",
    "\n",
    "dtypes = {\n",
    "        'ip'            : 'uint32',\n",
    "        'app'           : 'uint16',\n",
    "        'device'        : 'uint16',\n",
    "       # 'os'            : 'uint16',\n",
    "        'channel'       : 'uint16'\n",
    "#         'is_attributed' : 'uint8', # 【consider bool?need test】\n",
    "        }\n",
    "\n",
    "print('loading train data...',frm,'to',to)\n",
    "# usecols:Using this parameter results in much faster parsing time and lower memory usage.\n",
    "train_df = pd.read_csv(\"../input/train.csv\",skiprows=range(1,frm), nrows=to-frm, dtype=dtypes, usecols=['ip','app','device','channel'])\n",
    "\n",
    "print('loading test data...')\n",
    "if debug:\n",
    "    test_df = pd.read_csv(\"../input/test_supplement.csv\", nrows=100000, parse_dates=['click_time'], dtype=dtypes, usecols=['ip','app','device','os', 'channel', 'click_time', 'click_id'])\n",
    "else:\n",
    "    test_df = pd.read_csv(\"../input/test_supplement.csv\",dtype=dtypes, usecols=['ip','app','device', 'channel'])\n",
    "\n",
    "print('Combine test_df and train_df...')\n",
    "len_train = len(train_df)\n",
    "# Append rows of other to the end of this frame, returning a new object.\n",
    "# 【consider using concat more effiencent?add two more useless columns?】\n",
    "train_df=train_df.append(test_df) # Shouldn't process individually,because of lots of count,mean,var variables\n",
    "# train_df['is_attributed'].fillna(-1,inplace=True)\n",
    "# train_df['is_attributed'] = train_df['is_attributed'].astype('uint8',copy=False)\n",
    "del test_df\n",
    "gc.collect()\n",
    "\n",
    "print('Extracting hour and day and add 8h...')\n",
    "#     print(type(train_df['click_time']),type(pd.to_datetime(train_df.click_time))) # Series\n",
    "#     print(train_df['click_time'],pd.to_datetime(train_df.click_time)) # dtype: datetime64[ns]\n",
    "# http://pandas.pydata.org/pandas-docs/stable/timeseries.html\n",
    "#     print(train_df.click_time.head(500)) # 500 data before 6th 16:00\n",
    "# train_df.click_time = train_df.click_time + DateOffset(hours=8)\n",
    "# #     print(train_df.click_time.head(500))\n",
    "# train_df['hour'] = train_df.click_time.dt.hour.astype('uint8')\n",
    "# train_df['day'] = train_df.click_time.dt.day.astype('uint8')\n",
    "# gc.collect()\n",
    "\n",
    "#=====================================================================================================\n",
    "print('Combining new features...')\n",
    "\n",
    "# train_df['click_time'] = (train_df['click_time'].astype(np.int64,copy=False) // 10 ** 9).astype(np.int32,copy=False)\n",
    "# train_df['nextClick'] = (train_df.groupby(['ip', 'app', 'device', 'os']).click_time.shift(-1) - train_df.click_time).astype(np.float32,copy=False)\n",
    "\n",
    "# feature1：\n",
    "# train_df['nextClick2'] = (train_df.groupby(['ip', 'app', 'device', 'os','channel']).click_time.shift(-1) - train_df.click_time).astype(np.float32,copy=False)\n",
    "# train_df['nextClick3'] = (train_df.groupby(['ip', 'channel', 'device', 'os']).click_time.shift(-1) - train_df.click_time).astype(np.float32,copy=False)\n",
    "# train_df['nextClick4'] = (train_df.groupby(['app', 'device', 'channel']).click_time.shift(-1) - train_df.click_time).astype(np.float32,copy=False)\n",
    "# train_df['nextClick5'] = (train_df.groupby(['ip', 'os', 'device']).click_time.shift(-1) - train_df.click_time).astype(np.float32,copy=False)\n",
    "# 好用！：['app', 'device', 'channel']，['ip', 'app', 'device', 'os','channel']，['ip', 'app', 'device', 'os']\n",
    "\n",
    "# feature2：\n",
    "# print(train_df.groupby(['ip','channel'])) # <pandas.core.groupby.DataFrameGroupBy object at 0x000002C9D7C522E8>\n",
    "# print(train_df.groupby(['ip','channel']).click_time) # <pandas.core.groupby.SeriesGroupBy object at 0x000002C9D7479748>\n",
    "# print(train_df.click_time)\n",
    "# print(train_df.groupby(['ip','channel']).click_time.shift(+1))\n",
    "# print(train_df.click_time - train_df.groupby(['ip','channel']).click_time.shift(+1))\n",
    "# DataFrameGroupBy.shift:Shift index by desired number of periods with an optional time freq\n",
    "# train_df['prevClick'] = (train_df.click_time - train_df.groupby(['ip','channel']).click_time.shift(+1)).astype(np.float32,copy=False)\n",
    "# train_df['prevClick2'] = (train_df.click_time - train_df.groupby(['ip', 'app', 'device', 'os']).click_time.shift(+1)).astype(np.float32,copy=False)\n",
    "# train_df['prevClick3'] = (train_df.click_time - train_df.groupby(['ip', 'app', 'device', 'os','channel']).click_time.shift(+1)).astype(np.float32,copy=False)\n",
    "# train_df['prevClick4'] = (train_df.click_time - train_df.groupby(['app', 'device', 'channel']).click_time.shift(+1)).astype(np.float32,copy=False)\n",
    "# train_df['prevClick5'] = (train_df.click_time - train_df.groupby(['ip', 'os', 'device']).click_time.shift(+1)).astype(np.float32,copy=False)\n",
    "\n",
    "# feature3:\n",
    "# print(train_df[['ip','app']].groupby(['ip','app']).size())\n",
    "# print(train_df[['ip','app', 'channel']].groupby(['ip', 'app'])[['channel']].count()) # 完全相同\n",
    "# print(train_df[['ip','app']].groupby(['ip','app']).count()) # 必须任意加一个无关的列\n",
    "# train_df = do_countuniq( train_df, ['ip'], 'channel', 'B0', show_max=False)\n",
    "# train_df['nextClick6'] = (train_df.groupby(['ip', 'os', 'channel','app']).click_time.shift(-1) - train_df.click_time).astype(np.float32,copy=False)\n",
    "# train_df = do_count( train_df, ['app', 'channel'], 'B1', show_max=False )\n",
    "# train_df = do_count( train_df, ['app', 'channel','hour'], 'B2', show_max=False )\n",
    "# train_df = do_count( train_df, ['app', 'os'], 'B3', show_max=False )\n",
    "# train_df = do_count( train_df, ['app', 'os','channel'], 'B4', show_max=False )\n",
    "\n",
    "# feature4:\n",
    "train_df = do_mean( train_df, ['ip', 'app'], 'channel', 'C0', show_max=False )\n",
    "train_df = do_mean( train_df, ['ip', 'device'], 'channel', 'C1', show_max=False )\n",
    "\n",
    "\n",
    "# train_df.drop(['click_time','ip','day','channel','is_attributed','os','device','app','click_id','hour'], axis=1, inplace=True)\n",
    "train_df.drop(['ip','channel','device','app'], axis=1, inplace=True)\n",
    "gc.collect()\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------\n",
    "print(\"vars and data type: \")\n",
    "# Warning:A value is trying to be set on a copy of a slice from a DataFrame: only test_df\n",
    "test_df = train_df[len_train:]\n",
    "val_df = train_df[(len_train-val_size):len_train] # Validation set\n",
    "train_df = train_df[:(len_train-val_size)]\n",
    "gc.collect()\n",
    "\n",
    "print('Generate real testset from test_supplement...')\n",
    "test_df_real = test_df[21290876:27493809]\n",
    "test_df_real = pd.concat([test_df_real,test_df[35678696:41791910]], copy=False)\n",
    "test_df_real = pd.concat([test_df_real,test_df[48109937:54584259]], copy=False)\n",
    "test_df = test_df_real\n",
    "gc.collect()\n",
    "\n",
    "print(\"train size: \", len(train_df),train_df.head())\n",
    "print(\"valid size: \", len(val_df))\n",
    "print(\"test size : \", len(test_df))\n",
    "print(test_df.columns)\n",
    "\n",
    "print('Converting train/valid into float32...')\n",
    "train_df = train_df.astype('float32',copy=False) # categories类型也转换为float32：精度没有问题\n",
    "val_df = val_df.astype('float32',copy=False)\n",
    "print(train_df.info())\n",
    "print(val_df.info())\n",
    "print(test_df.info())\n",
    "gc.collect()\n",
    "\n",
    "print('Saving data to disk...')\n",
    "train_df.to_pickle('./train_df_feature4.pkl')\n",
    "val_df.to_pickle('./val_df_feature4.pkl')\n",
    "test_df.to_pickle('./test_df_feature4.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
